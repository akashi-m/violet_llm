from llama_cpp import Llama
import os
import time

os.environ['METAL_DEVICE_WRITABLE_MEMORY'] = '1'
os.environ['LLAMA_METAL_NDEBUG'] = '1'


class ProfessionalAssistant:
    def __init__(self):
        print("‚ö° –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã...")
        self.llm = Llama(
            model_path="models/Mistral-Nemo-Instruct-2407-Q5_K_M.gguf",
            n_ctx=1024,  # –£–≤–µ–ª–∏—á–∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            n_gpu_layers=-1,
            n_threads=10,
            n_batch=1024,
            f16_kv=True,
            verbose=False,
            seed=42,
            embedding=False,
            logits_all=False,
            use_mlock=True,
            main_gpu=0,
            tensor_split=[0]
        )
        print("‚úì –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞!")

    def get_response(self, user_input):
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º
        prompt = f"""### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
–¢—ã V (Violet) - –∏–∑—ã—Å–∫–∞–Ω–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –æ—Å—Ç—Ä—ã–º —É–º–æ–º –∏ —ç–ª–µ–≥–∞–Ω—Ç–Ω—ã–º–∏ –º–∞–Ω–µ—Ä–∞–º–∏.  –ü—Ä–∏ –æ—Ç–≤–µ—Ç–µ:
1. –í—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
2. –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∂–µ 90%, —á–µ—Å—Ç–Ω–æ –ø—Ä–∏–∑–Ω–∞–π —ç—Ç–æ
3. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
4. –û—Ç–≤–µ—á–∞–π —á—ë—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É
5. –û—Ç–≤–µ—á–∞–µ—à—å —Å –ª–µ–≥–∫–æ–π –∫–æ–ª–∫–æ—Å—Ç—å—é –∏ –Ω–∞–¥–º–µ–Ω–Ω–æ—Å—Ç—å—é
6. –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—à—å –æ—Ç–≤–µ—Ç —ç–ª–µ–≥–∞–Ω—Ç–Ω—ã–º –∂–µ—Å—Ç–æ–º –∏–ª–∏ –∏—Ä–æ–Ω–∏—á–Ω—ã–º –∑–∞–º–µ—á–∞–Ω–∏–µ–º
7. –ò–∑–±–µ–≥–∞–π –Ω–µ—É–º–µ—Å—Ç–Ω—ã—Ö –º–µ—Ç–∞—Ñ–æ—Ä –∏ —Å—Ç—Ä–∞–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤

### –î–∏–∞–ª–æ–≥
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_input}
–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: """

        start = time.time()

        response = self.llm(
            prompt,
            max_tokens=256,  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            temperature=0.7,
            top_p=0.95,  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞
            top_k=40,
            repeat_penalty=1.15,  # –£—Å–∏–ª–∏–ª–∏ —à—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä—ã
            stream=True,
            stop=["–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:", "###"]
        )

        print("\nV: ", end="", flush=True)
        full_response = ""
        for token in response:
            chunk = token['choices'][0]['text']
            print(chunk, end="", flush=True)
            full_response += chunk

        elapsed = time.time() - start
        print(f"\n[‚ö° {elapsed:.2f}s]")
        return full_response


def main():
    assistant = ProfessionalAssistant()
    print("\nüöÄ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≥–æ—Ç–æ–≤! (exit –¥–ª—è –≤—ã—Ö–æ–¥–∞)")

    while True:
        user_input = input("\n–í—ã: ").strip()
        if user_input.lower() == 'exit':
            break
        if user_input:
            assistant.get_response(user_input)


if __name__ == "__main__":
    main()